{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding custom decision tree algorithm (modified CART)\n",
    "## Part 2: Gini impurity\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "For a **general overview** of the custom decision tree algorithm that I will build in this series, please refer to the Part 1. This and the following parts will analyze the algorithm bottom-up, from the specifics of how to split the data in each node of the tree, up to the construction of the tree itself.\n",
    "\n",
    "We begin by exploring the **Gini impurity** of a dataset. This part will be very simple from the coding viewpoint, but it will require some understanding of probability theory. I will start by developing conceptual understanding, and will provide the code in the very end since it is quite simple.\n",
    "\n",
    "As already discussed, Gini impurity, or Gini for short, is a measure of how \"pure\" a dataset is. Purity, in this context, refers to the number of different values that appear in a list. \n",
    "Ultimately, our goal will be to generate very pure datasets. Imagine it this way, if you want to separate some business' customers into those who are likely to purchase a product and those who are not, you would like to ultimately have a separate list for each of those two categories. You don't want to have a list of buyers with many non-buyers on it and viceversa. *In other words you want to have two \"pure\" lists - one with buyers and one with non-buyers.*\n",
    "\n",
    "In terms of a decision tree, the **decision path** will be some number of conditions. You will run a dataset with all your customers through a tree and the tree will ask questions such as \"is this person older than 30\", \"did the person purchase something in the past 30 days\". Finally, the tree will produce lists of customers for all combinations of answers to these questions. There will be a list of customers older than 30 who didn't purchase anything in the past 30 days, and so on. Ideally, each such list will contain only buyers or only non-buyers. In practice, there will be a combination of both, but again, ideally the more pure the list the better it is.\n",
    "\n",
    "The **point of the decision tree is to \"learn\" which conditions to ask**, so that the final lists are as pure as possible. For example, by learning a tree on some training data, it has to deduce that the first condition on which to split the data is age, and that the optimal age for a split is 30. For each possible answer (yes/no), it then has to find the next variable on which to split, and the value of that variable on which to split. The choice of the variable, and the value of the variable, will always be such as to minimize the impurity of the resulting lists.\n",
    "\n",
    "### Gini impurity - conceptual analysis through examples\n",
    "\n",
    "Let's look at what Gini impurity formula does on a couple of examples.\n",
    "\n",
    "Given a list of elements, some of which repeat, we could **interpret the formula as follows: it provides the probability of drawing two distinct elements from a list** (in two drawings with replacement).\n",
    "\n",
    "First, for every unique element A appearing in the list, it computes the probability that by drawing two elements of a list, we draw A and another element, B, where B is different from A. \n",
    "Then, it sums all these probabilities together, thereby obtaining a value that can be interpreted as a union of the original probabilities, so probability that I draw: A and non-A,or B and non-B, or C and non-C, etc.\n",
    "\n",
    "I will now use the function that computes Gini impurity to provide you with the intuition, and then I will give you the code for the function. Let us begin by importing numpy, generating a sample list, *example*, and a list of unique elements that appear in *example*, which we call *list_of_elements*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = np.array([0,0,0,1,1,1]) #example list\n",
    "list_of_elements = [0,1] #list of unique elements in example\n",
    "get_gini_impurity(example, list_of_elements) #compute Gini impurity of the example list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we got the above result. Think of it this way, in the example, there is equal number of 0s and 1s (the order of the numbers is not important). The probability of drawing 0 and a non-0, is $ \\frac{1}{2}\\times\\frac{1}{2} = \\frac{1}{4} $. Similarly, the probability of drawing a 1 and a non-1 is $\\frac{1}{4}$.\n",
    "\n",
    "The probability of drawing two different numbers in two drawings with replacement is thus $ \\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2} = 0.5 $\n",
    "\n",
    "Just to prove that the order of the numbers is not important:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = np.array([0,1,0,1,0,1])\n",
    "get_gini_impurity(example, list_of_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now introduce one more label, and take a list in which each of the three labels (1,2,3) appear equal number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = np.array([0,0,0,1,1,1,2,2,2]) #example list\n",
    "list_of_elements = [0,1,2] #list of unique elements in example\n",
    "get_gini_impurity(example, list_of_elements) #compute Gini impurity of the example list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the result by computing the Gini following our interpretation. The probability of drawing any element (0,1, or 2) and a different element (1 or 2, 0 or 2, 0 or 1, respectively) is $\\frac{1}{3}\\times\\frac{2}{3}=\\frac{2}{9}$ since each element appears 1/3 of the time.\n",
    "\n",
    "The probability of drawing any such pair is 3 times the above probability, $3\\times\\frac{2}{9}=\\frac{6}{9}=\\frac{2}{3} \\simeq 0.666$.\n",
    "\n",
    "One final example, let one element appear twice as often as another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444445"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = np.array([0,0,0,0,1,1,]) #example list\n",
    "list_of_elements = [0,1,2] #list of unique elements in example\n",
    "get_gini_impurity(example, list_of_elements) #compute Gini impurity of the example list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, note that the formula doesn't care that there is potentially more than 2 labels. It never sees the element \"2\" so it drops out.\n",
    "\n",
    "The probabilities work as follows. For 0 and non-0 we have: $\\frac{4}{6}\\times\\frac{2}{6}=\\frac{2}{3}\\times\\frac{1}{3}=\\frac{2}{9}$. For 1 and non-1 we have: $\\frac{2}{6}\\times\\frac{4}{6}=\\frac{2}{9}$ (Symmetric since there's only two elements.) Overall, we can draw 0 and non-0 or 1 and non-1 which is $2\\times \\frac{2}{9} = \\frac{4}{9} \\simeq 0.444$.\n",
    "\n",
    "### Gini impurity - the code\n",
    "\n",
    "Let us now go to the simple code of the function that was computing Gini impurity for us. The description of the code is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute gini coefficient of an array, with given labels\n",
    "def get_gini_impurity(array, labels_list):\n",
    "    '''Computes Gini impurity of the given array of labels. \n",
    "    array [np.array] is the array for which Gini is computed.\n",
    "    labels_list [np.array] is the list of labels in the array.'''\n",
    "    label_probabilities = []\n",
    "    array_length = len(array)\n",
    "    if array_length==0:\n",
    "        return 0\n",
    "    #if array length is not zero\n",
    "    for label in labels_list:\n",
    "        label_probabilities.append(np.sum(array==label)/array_length)\n",
    "    return np.sum(label_probabilities*( np.ones(len(label_probabilities))-label_probabilities ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **run through the code**.\n",
    "\n",
    "*label_probabilities* will hold probabilities to find each unique element of the list in the list.\n",
    "\n",
    "If the list that is passed to the function is empty, the function returns a zero, as if the list is completely pure.\n",
    "\n",
    "We loop over all unique elements in the list. For each of them we compute a probability to find this element in the list and we append it to the list of probabilities.\n",
    "\n",
    "In the final line, inside of np.sum, we multiply, element-wise, probabilities with one-minus-probabilities. This is the step that gives us the probability of drawing one element and a different element from the list.\n",
    "These probabilities are then all summed by np.sum, giving the overall probability to draw two different numbers from the list.\n",
    "\n",
    "What is the **complexity** of this code? Well, everything until the loop is $\\mathcal{O}(1)$.\n",
    "The loop goes through all labels, and for each label it has to do comparison with all elements of the list and then to sum up all *True*'s. This is clearly $\\mathcal{O}(m\\times n)$, where m is the number of unique labels, and n is the length of your dataset. In practice, you will pass the column with the target values to this function, so m will be 2, or some rather low number in case of classification. \n",
    "The size of the dataset will drop exponentially with the level of layers in the tree. If you have 100k records at root and split them equally, you'll have two nodes with 50k records each at the following level. At second level, following the same logic, you'd have 4 nodes with 25k records each. So the time to clear the node drops exponentially, but the time to clear a level of the tree is approximately constant.\n",
    "In practice, I did not find any need to think about speeding up this routine. The idea of optimization will come up more when we discuss splitting the nodes.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "I've given you an overview of where computation of the Gini impurity comes up and what it is used for. \n",
    "We've followed this with a brief conceptual analysis of Gini impurity, and finally we've looked at the code that computes Gini.\n",
    "\n",
    "I hoped you enjoyed this part! The next one is Part 3 in which we look at how to find the ideal threshold on which to split a given feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
